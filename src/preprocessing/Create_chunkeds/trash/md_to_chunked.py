import sys
import json
import re
import uuid
from pathlib import Path
from datetime import datetime


class PueMetadataParser:
    """
    –ü–∞—Ä—Å–µ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ pipeline_2.md.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–ª—é—á–∏ —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã: Document, Section, Chapter, Paragraph, Clause, Content.
    """
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–ª—é—á–∞–º–∏ —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã (–∫–∞–∫ –≤ –¢–ó)
        self.metadata = {
            "Document": "",
            "Section": "",
            "Chapter": "",
            "Paragraph": "",
            "Clause": ""
        }
    
    def parse_line(self, line: str) -> dict | None:
        """
        –ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –∏–ª–∏ None.
        """
        line = line.strip()
        if not line:
            return None
        
        # 1. Document (### –ù–∞–∑–≤–∞–Ω–∏–µ)
        if match := re.match(r'^###\s+(.+)$', line):
            self.metadata["Document"] = match.group(1).strip()
            return self._make_record("")
        
        # 2. Section (## –†–∞–∑–¥–µ–ª {X})
        if match := re.match(r'^##\s+–†–∞–∑–¥–µ–ª\s+(\d+)\s*(.*)$', line):
            section_title = match.group(2).strip()
            if section_title:
                self.metadata["Section"] = f"–†–∞–∑–¥–µ–ª {match.group(1)} {section_title}".strip()
            else:
                self.metadata["Section"] = f"–†–∞–∑–¥–µ–ª {match.group(1)}".strip()
            self._reset(['Chapter', 'Paragraph', 'Clause'])
            return self._make_record("")
        
        # 3. Chapter (# –ì–ª–∞–≤–∞ {X.Y})
        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å # –ì–ª–∞–≤–∞, –ù–û –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¢–∞–±–ª–∏—Ü–∞ –∏–ª–∏ –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ
        if re.match(r'^#\s+–ì–ª–∞–≤–∞\s+', line):
            if '–¢–∞–±–ª–∏—Ü–∞' not in line and '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ' not in line:
                match = re.match(r'^#\s+–ì–ª–∞–≤–∞\s+(\d+\.\d+)\s*[-‚Äì:]\s*(.*)$', line)
                if match:
                    chapter_title = match.group(2).strip()
                    if chapter_title:
                        self.metadata["Chapter"] = f"–ì–ª–∞–≤–∞ {match.group(1)} - {chapter_title}".strip()
                    else:
                        self.metadata["Chapter"] = f"–ì–ª–∞–≤–∞ {match.group(1)}".strip()
                    self._reset(['Paragraph', 'Clause'])
                    return self._make_record("")
        
        # 4. Paragraph (# –ù–∞–∑–≤–∞–Ω–∏–µ)
        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å #, –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, –ù–ï–¢ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if re.match(r'^#\s+.+$', line):
            skip_words = ['–ì–ª–∞–≤–∞', '–¢–∞–±–ª–∏—Ü–∞', '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ']
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (–≤–∫–ª—é—á–∞—è #–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞)
            if not any(word in line for word in skip_words):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ #
                text = re.sub(r'^#\s*', '', line).strip()
                if text:  # –ï—Å–ª–∏ –ø–æ—Å–ª–µ # –æ—Å—Ç–∞–ª—Å—è —Ç–µ–∫—Å—Ç
                    self.metadata["Paragraph"] = text
                    self._reset(['Clause'])
                    return self._make_record("")
                # else: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç -> –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–Ω–∏—á–µ–≥–æ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º)
        
        # 5. Clause ((X.Y.Z) –¢–µ–∫—Å—Ç) –∏–ª–∏ (X.Y.Z. –¢–µ–∫—Å—Ç)
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ (1.2.3) –¢–µ–∫—Å—Ç
        if match := re.match(r'^\((\d+\.\d+\.\d+)\)\s+(.*)$', line):
            self.metadata["Clause"] = match.group(1)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å –Ω–æ–º–µ—Ä–æ–º –ø—É–Ω–∫—Ç–∞
            return self._make_record(line)
        
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ 1.2.3. –¢–µ–∫—Å—Ç (–±–µ–∑ —Å–∫–æ–±–æ–∫, —Å —Ç–æ—á–∫–æ–π –≤ –∫–æ–Ω—Ü–µ)
        if match := re.match(r'^(\d+\.\d+\.\d+)\.\s+(.*)$', line):
            self.metadata["Clause"] = match.group(1)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å –Ω–æ–º–µ—Ä–æ–º –ø—É–Ω–∫—Ç–∞
            return self._make_record(line)
        
        # 6. Content (–û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç)
        # –û—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ–∫—É—â–µ–º—É –∞–∫—Ç–∏–≤–Ω–æ–º—É –ø—É–Ω–∫—Ç—É (Clause)
        if self.metadata["Clause"]:
            return self._make_record(line)

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥–æ—à–ª–æ –∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞
        return None
    
    def _reset(self, keys: list):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É"""
        for key in keys:
            self.metadata[key] = ""
    
    def _make_record(self, content: str) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ø–∏—é —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º"""
        return {**self.metadata, "Content": content}


def chunk_document(content, source_file):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —á–∞–Ω–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è PueMetadataParser.
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ Clause - –∫–∞–∂–¥—ã–π Clause —Å–æ–∑–¥–∞–µ—Ç –æ–¥–∏–Ω —á–∞–Ω–∫.
    """
    lines = content.split('\n')
    parser = PueMetadataParser()
    chunks = []

    current_clause_content = []
    current_metadata = None
    clause_count = 0
    
    for line in lines:
        record = parser.parse_line(line)
        
        if record is None:
            # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π –ø—É–Ω–∫—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –∫ –∫–æ–Ω—Ç–µ–Ω—Ç—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            if current_metadata and current_metadata.get("Clause"):
                current_clause_content.append("")
            continue

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (Document, Section, Chapter, Paragraph –º–æ–≥—É—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è)
        clause_id = record.get("Clause", "")
        content_text = record.get("Content", "")
        paragraph_text = record.get("Paragraph", "")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –Ω–æ–≤—ã–º Paragraph
        is_new_paragraph = paragraph_text and (
            not current_metadata or 
            current_metadata.get("Paragraph", "") != paragraph_text
        )
        
        # –ï—Å–ª–∏ –ø–æ—è–≤–∏–ª—Å—è –Ω–æ–≤—ã–π Paragraph, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–∏–π Clause (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if is_new_paragraph and current_metadata and current_metadata.get("Clause"):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —á–∞–Ω–∫ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –Ω–æ–≤–æ–≥–æ Paragraph
            if current_clause_content:
                chunks.append(create_chunk_obj(current_metadata, current_clause_content, source_file))
            current_clause_content = []
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º Clause –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫ –∫–∞–∫ Paragraph —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç Clause
            current_metadata = record.copy()
            current_metadata["Clause"] = ""
            continue
        
        # –ï—Å–ª–∏ –ø–æ—è–≤–∏–ª—Å—è –Ω–æ–≤—ã–π Clause, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —á–∞–Ω–∫
        if clause_id:
            clause_count += 1
            if current_metadata and current_metadata.get("Clause") and current_metadata.get("Clause") != clause_id:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —á–∞–Ω–∫
                if current_clause_content:
                    chunks.append(create_chunk_obj(current_metadata, current_clause_content, source_file))
                current_clause_content = []
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–æ–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞
            current_metadata = record.copy()
            # –î–ª—è Clause content_text —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å –Ω–æ–º–µ—Ä–æ–º –ø—É–Ω–∫—Ç–∞
            current_clause_content.append(content_text)
        elif current_metadata and current_metadata.get("Clause"):
            # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            # content_text —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫—É –±–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            current_clause_content.append(content_text if content_text else line)
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–º–æ–≥—É—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è Document, Section, Chapter)
            # –ù–û –ù–ï Paragraph - Paragraph —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤—ã—à–µ –∏ –∑–∞–≤–µ—Ä—à–∏–ª –ø—Ä–µ–¥—ã–¥—É—â–∏–π Clause
            if current_metadata:
                for key in ["Document", "Section", "Chapter"]:
                    if record.get(key):
                        current_metadata[key] = record[key]
        else:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ Clause
            # (–¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Å–Ω–∞—á–∞–ª–∞ –∏–¥—É—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏, –∞ –ø–æ—Ç–æ–º –ø—É–Ω–∫—Ç—ã)
            if not current_metadata:
                current_metadata = record.copy()
            else:
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –Ω–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç, –µ—Å–ª–∏ –Ω–µ—Ç Clause
                for key in ["Document", "Section", "Chapter", "Paragraph"]:
                    if record.get(key):
                        current_metadata[key] = record[key]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
    if current_metadata and current_metadata.get("Clause") and current_clause_content:
        chunks.append(create_chunk_obj(current_metadata, current_clause_content, source_file))
    
    if clause_count == 0:
        print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞ (Clause) –≤ —Ñ–∞–π–ª–µ.")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(lines)}")
        print(f"   –¢–µ–∫—É—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: Document='{parser.metadata.get('Document')}', Section='{parser.metadata.get('Section')}', Chapter='{parser.metadata.get('Chapter')}'")
    
    return chunks


def create_chunk_obj(metadata_record, content_lines, source_file):
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç JSON-–æ–±—ä–µ–∫—Ç –¥–ª—è —á–∞–Ω–∫–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"""
    text_content = "\n".join(content_lines).strip()
    
    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
    clause_id = metadata_record.get("Clause", "unknown")
    chunk_id = f"pue_{clause_id}_{uuid.uuid4().hex[:8]}"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü –∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫
    has_tables = "# –¢–∞–±–ª–∏—Ü–∞" in text_content or "|" in text_content
    has_images = "![" in text_content
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞
    context_parts = []
    if metadata_record.get("Document"):
        context_parts.append(metadata_record["Document"])
    if metadata_record.get("Section"):
        context_parts.append(metadata_record["Section"])
    if metadata_record.get("Chapter"):
        context_parts.append(metadata_record["Chapter"])
    if metadata_record.get("Paragraph"):
        context_parts.append(metadata_record["Paragraph"])
    
    context_header = ". ".join(context_parts) + "." if context_parts else ""
    full_content = f"{context_header}\n\n{text_content}" if context_header else text_content
    
    chunk_data = {
        "id": chunk_id,
        "metadata": {
            "Document": metadata_record.get("Document", ""),
            "Section": metadata_record.get("Section", ""),
            "Chapter": metadata_record.get("Chapter", ""),
            "Paragraph": metadata_record.get("Paragraph", ""),
            "Clause": metadata_record.get("Clause", ""),
            "contains_tables": has_tables,
            "contains_images": has_images,
            "source_file": source_file
        },
        "content": full_content,
        "created_at": datetime.now().isoformat()
    }
    
    return chunk_data


def generate_chunked_file(md_path, output_dir):
    md_path = Path(md_path).resolve()

    if md_path.suffix.lower() != '.md':
        print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª '{md_path}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è .md —Ñ–∞–π–ª–æ–º.")
        sys.exit(1)

    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {md_path.name}")

    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    try:
        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        sys.exit(1)

    # –ß–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
    chunks = chunk_document(content, md_path.name)
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")

    # –ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –∏–º—è_–∏—Å—Ö–æ–¥–Ω–æ–≥–æ.chunked.jsonl
    output_filename = f"{md_path.stem}.chunked.jsonl"
    output_path = output_dir / output_filename

    # –ó–∞–ø–∏—Å—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - –≤–∞–ª–∏–¥–Ω—ã–π JSON)
    try:
        if len(chunks) == 0:
            print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞. –§–∞–π–ª –Ω–µ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω.")
            print(f"üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞—é—Ç—Å—è –ø—É–Ω–∫—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ:")
            print(f"   - (1.2.3) –¢–µ–∫—Å—Ç")
            print(f"   - 1.2.3. –¢–µ–∫—Å—Ç")
            return None
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for chunk in chunks:
                json_line = json.dumps(chunk, ensure_ascii=False)
                f.write(json_line + '\n')

        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤.")
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        return str(output_path)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞: {e}")
        sys.exit(1)

# –ü—É—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ã)
# DEFAULT_INPUT_FILE = r"D:\my-diplom\Diplom_AI\data\extracted\1.8.md"
# DEFAULT_OUTPUT_DIR = r"D:\my-diplom\Diplom_AI\data\chunked"

DEFAULT_OUTPUT_DIR = r"X:\–£—á–µ–±–∞_–£–ò–ò\–ò—Ç–æ–≥–æ–≤—ã_–ü—Ä–æ–µ–∫—Ç\data\chunked"
DEFAULT_INPUT_FILE = r"X:\–£—á–µ–±–∞_–£–ò–ò\–ò—Ç–æ–≥–æ–≤—ã_–ü—Ä–æ–µ–∫—Ç\data\extracted\1.7.md"

if __name__ == "__main__":
    input_dir_arg = None
    output_dir_arg = None
    try:
        # –†–∞–±–æ—á–∞—è –≤–µ—Ä—Å–∏—è: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        if len(sys.argv) == 2 and sys.argv[1].strip():
            input_dir_arg = sys.argv[1]
        elif len(sys.argv) == 3 and sys.argv[1].strip() and sys.argv[2].strip():
            input_dir_arg = sys.argv[1]
            output_dir_arg = sys.argv[2]
        else:
            # –î–ª—è —Ç–µ—Å—Ç–æ–≤: –∏—Å–ø–æ–ª—å–∑—É–µ–º file_docx
            input_dir_arg = DEFAULT_INPUT_FILE
            output_dir_arg = DEFAULT_OUTPUT_DIR

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        md_path = Path(input_dir_arg)
        if not md_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_dir_arg}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º output_dir
        if output_dir_arg:
            output_dir = Path(output_dir_arg)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if not output_dir.exists():
                raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {output_dir_arg}")
            if not output_dir.is_dir():
                raise NotADirectoryError(f"–£–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {output_dir_arg}")
        else:
            output_dir = md_path.parent

        chunked_content = generate_chunked_file(input_dir_arg, output_dir)
    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python md_to_chunked.py <—Ñ–∞–π–ª.md> [output_dir]")
        sys.exit(1)
    except NotADirectoryError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python md_to_chunked.py <—Ñ–∞–π–ª.md> [output_dir]")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python md_to_chunked.py <—Ñ–∞–π–ª.md> [output_dir]")
        sys.exit(1)