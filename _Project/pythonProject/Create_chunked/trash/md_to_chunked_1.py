import sys
import json
import re
import uuid
from pathlib import Path
from datetime import datetime


class PueMetadataParser:
    """
    –ü–∞—Ä—Å–µ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ pipeline_2.md.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–ª—é—á–∏ —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã: Document, Section, Chapter, Paragraph, Clause, Content.
    """

    def __init__(self):
        self.metadata = {
            "Document": "",
            "Section": "",
            "Chapter": "",
            "Paragraph": "",
            "Clause": ""
        }

    def parse_line(self, line: str) -> dict | None:
        """
        –ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –∏–ª–∏ None.
        """
        line = line.strip()
        if not line:
            return None

        # 1. Document (### –ù–∞–∑–≤–∞–Ω–∏–µ)
        if match := re.match(r'^###\s+(.+)$', line):
            self.metadata["Document"] = match.group(1).strip()
            return self._make_record("")

        # 2. Section (## –†–∞–∑–¥–µ–ª {X})
        if match := re.match(r'^##\s+–†–∞–∑–¥–µ–ª\s+(\d+)\s*(.*)$', line):
            section_title = match.group(2).strip()
            if section_title:
                self.metadata["Section"] = f"–†–∞–∑–¥–µ–ª {match.group(1)} {section_title}".strip()
            else:
                self.metadata["Section"] = f"–†–∞–∑–¥–µ–ª {match.group(1)}".strip()
            self._reset(['Chapter', 'Paragraph', 'Clause'])
            return self._make_record("")

        # 3. Chapter (# –ì–ª–∞–≤–∞ {X.Y})
        if re.match(r'^#\s+–ì–ª–∞–≤–∞\s+', line):
            if '–¢–∞–±–ª–∏—Ü–∞' not in line and '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ' not in line:
                match = re.match(r'^#\s+–ì–ª–∞–≤–∞\s+(\d+\.\d+)\s*[-‚Äì:]\s*(.*)$', line)
                if match:
                    chapter_title = match.group(2).strip()
                    if chapter_title:
                        self.metadata["Chapter"] = f"–ì–ª–∞–≤–∞ {match.group(1)} - {chapter_title}".strip()
                    else:
                        self.metadata["Chapter"] = f"–ì–ª–∞–≤–∞ {match.group(1)}".strip()
                    self._reset(['Paragraph', 'Clause'])
                    return self._make_record("")

        # 4. Paragraph (# –ù–∞–∑–≤–∞–Ω–∏–µ) - –Ω–æ –Ω–µ –ì–ª–∞–≤–∞/–¢–∞–±–ª–∏—Ü–∞/–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ
        if re.match(r'^#\s+.+$', line):
            skip_words = ['–ì–ª–∞–≤–∞', '–¢–∞–±–ª–∏—Ü–∞', '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ']
            if not any(word in line for word in skip_words):
                text = re.sub(r'^#\s*', '', line).strip()
                if text:
                    self.metadata["Paragraph"] = text
                    self._reset(['Clause'])
                    return self._make_record("")

        # 5. Clause ((X.Y.Z) –¢–µ–∫—Å—Ç) –∏–ª–∏ (X.Y.Z. –¢–µ–∫—Å—Ç)
        if match := re.match(r'^\((\d+\.\d+\.\d+)\)\s+(.*)$', line):
            self.metadata["Clause"] = match.group(1)
            return self._make_record(line)

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ 1.2.3. –¢–µ–∫—Å—Ç (–±–µ–∑ —Å–∫–æ–±–æ–∫, —Å —Ç–æ—á–∫–æ–π –≤ –∫–æ–Ω—Ü–µ)
        if match := re.match(r'^(\d+\.\d+\.\d+)\.\s+(.*)$', line):
            self.metadata["Clause"] = match.group(1)
            return self._make_record(line)

        # 6. Content (–û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç) - –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ–∫—É—â–µ–º—É –∞–∫—Ç–∏–≤–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–ø–∏—Å—å –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç Clause - –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ Paragraph
        if self.metadata["Paragraph"] or self.metadata["Clause"]:
            return self._make_record(line)

        return None

    def _reset(self, keys: list):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É"""
        for key in keys:
            self.metadata[key] = ""

    def _make_record(self, content: str) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ø–∏—é —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º"""
        return {**self.metadata, "Content": content}


def chunk_document(content, source_file):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —á–∞–Ω–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è PueMetadataParser.
    –ö–ª—é—á–µ–≤–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç—Å—è –¥–∞–∂–µ –±–µ–∑ Clause, –µ—Å–ª–∏ –µ—Å—Ç—å Paragraph.
    """
    lines = content.split('\n')
    parser = PueMetadataParser()
    chunks = []

    # –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –±–ª–æ–∫–∞
    current_content = []
    current_metadata = None
    clause_count = 0
    has_clause_in_block = False

    for line in lines:
        record = parser.parse_line(line)

        if record is None:
            # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–∫—É—â–µ–º—É –∫–æ–Ω—Ç–µ–Ω—Ç—É –µ—Å–ª–∏ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π –±–ª–æ–∫
            if current_metadata and (current_metadata.get("Clause") or current_metadata.get("Paragraph")):
                current_content.append("")
            continue

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è
        clause_id = record.get("Clause", "")
        paragraph_text = record.get("Paragraph", "")
        content_text = record.get("Content", "")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø–∏—Å–∏
        is_new_chapter = record.get("Chapter") and (
                not current_metadata or
                current_metadata.get("Chapter", "") != record.get("Chapter", "")
        )
        is_new_paragraph = paragraph_text and (
                not current_metadata or
                current_metadata.get("Paragraph", "") != paragraph_text
        )
        is_new_clause = clause_id and (
                not current_metadata or
                current_metadata.get("Clause", "") != clause_id
        )

        # === –õ–æ–≥–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –±–ª–æ–∫–∞ ===

        # –ù–æ–≤—ã–π Chapter - –∑–∞–≤–µ—Ä—à–∞–µ–º –≤—Å—ë –ø—Ä–µ–¥—ã–¥—É—â–µ–µ
        if is_new_chapter and current_metadata and current_content:
            chunks.append(create_chunk_obj(current_metadata, current_content, source_file))
            current_content = []
            has_clause_in_block = False

        # –ù–æ–≤—ã–π Paragraph - –∑–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –±–ª–æ–∫ –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
        elif is_new_paragraph and current_metadata and current_content:
            chunks.append(create_chunk_obj(current_metadata, current_content, source_file))
            current_content = []
            has_clause_in_block = False

        # –ù–æ–≤—ã–π Clause - –∑–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π Clause –µ—Å–ª–∏ –µ—Å—Ç—å
        elif is_new_clause and current_metadata and current_metadata.get("Clause"):
            chunks.append(create_chunk_obj(current_metadata, current_content, source_file))
            current_content = []
            has_clause_in_block = False

        # === –õ–æ–≥–∏–∫–∞ –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ –±–ª–æ–∫–∞ ===

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if is_new_chapter or is_new_paragraph or is_new_clause or not current_metadata:
            current_metadata = record.copy()

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (Document, Section, Chapter –º–æ–≥—É—Ç –º–µ–Ω—è—Ç—å—Å—è)
        if current_metadata:
            for key in ["Document", "Section", "Chapter"]:
                if record.get(key):
                    current_metadata[key] = record[key]
            if paragraph_text:
                current_metadata["Paragraph"] = paragraph_text
            if clause_id:
                current_metadata["Clause"] = clause_id
                has_clause_in_block = True

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
        if content_text or (line.strip() and record is not None):
            current_content.append(content_text if content_text else line.strip())

    # === –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç ===
    if current_metadata and current_content:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã Paragraph –∏–ª–∏ Clause
        if current_metadata.get("Paragraph") or current_metadata.get("Clause"):
            chunks.append(create_chunk_obj(current_metadata, current_content, source_file))

    if clause_count == 0 and len(chunks) == 0:
        print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞ (Clause) –≤ —Ñ–∞–π–ª–µ.")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(lines)}")

    return chunks


def create_chunk_obj(metadata_record, content_lines, source_file):
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç JSON-–æ–±—ä–µ–∫—Ç –¥–ª—è —á–∞–Ω–∫–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"""
    text_content = "\n".join(content_lines).strip()

    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
    clause_id = metadata_record.get("Clause", "")
    paragraph_id = metadata_record.get("Paragraph", "")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –Ω–∞ –æ—Å–Ω–æ–≤–µ Clause –∏–ª–∏ Paragraph
    if clause_id:
        chunk_id = f"pue_{clause_id}_{uuid.uuid4().hex[:8]}"
    elif paragraph_id:
        # –î–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±–µ–∑ Clause –∏—Å–ø–æ–ª—å–∑—É–µ–º Paragraph + —Ö–µ—à –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_hash = hash(text_content) & 0xFFFFFFFF
        chunk_id = f"pue_para_{paragraph_id}_{content_hash:08x}"
    else:
        chunk_id = f"pue_unknown_{uuid.uuid4().hex[:8]}"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü –∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫
    has_tables = "# –¢–∞–±–ª–∏—Ü–∞" in text_content or "|" in text_content
    has_images = "![" in text_content

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞
    context_parts = []
    if metadata_record.get("Document"):
        context_parts.append(metadata_record["Document"])
    if metadata_record.get("Section"):
        context_parts.append(metadata_record["Section"])
    if metadata_record.get("Chapter"):
        context_parts.append(metadata_record["Chapter"])
    if metadata_record.get("Paragraph"):
        context_parts.append(metadata_record["Paragraph"])
    if metadata_record.get("Clause"):
        context_parts.append(f"–ü—É–Ω–∫—Ç {metadata_record['Clause']}")

    context_header = ". ".join(context_parts) + "." if context_parts else ""
    full_content = f"{context_header}\n\n{text_content}" if context_header else text_content

    chunk_data = {
        "id": chunk_id,
        "metadata": {
            "Document": metadata_record.get("Document", ""),
            "Section": metadata_record.get("Section", ""),
            "Chapter": metadata_record.get("Chapter", ""),
            "Paragraph": metadata_record.get("Paragraph", ""),
            "Clause": metadata_record.get("Clause", ""),
            "contains_tables": has_tables,
            "contains_images": has_images,
            "source_file": source_file
        },
        "content": full_content,
        "created_at": datetime.now().isoformat()
    }

    return chunk_data


def generate_chunked_file(md_path, output_dir):
    md_path = Path(md_path).resolve()

    if md_path.suffix.lower() != '.md':
        print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª '{md_path}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è .md —Ñ–∞–π–ª–æ–º.")
        sys.exit(1)

    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {md_path.name}")

    try:
        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        sys.exit(1)

    chunks = chunk_document(content, md_path.name)

    print(f"üîç –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")

    output_filename = f"{md_path.stem}.chunked.jsonl"
    output_path = output_dir / output_filename

    try:
        if len(chunks) == 0:
            print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞. –§–∞–π–ª –Ω–µ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω.")
            return None

        with open(output_path, 'w', encoding='utf-8') as f:
            for chunk in chunks:
                json_line = json.dumps(chunk, ensure_ascii=False)
                f.write(json_line + '\n')

        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤.")
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        return str(output_path)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞: {e}")
        sys.exit(1)


DEFAULT_OUTPUT_DIR = r"X:\–£—á–µ–±–∞_–£–ò–ò\–ò—Ç–æ–≥–æ–≤—ã_–ü—Ä–æ–µ–∫—Ç\data\chunked"
DEFAULT_INPUT_FILE = r"X:\–£—á–µ–±–∞_–£–ò–ò\–ò—Ç–æ–≥–æ–≤—ã_–ü—Ä–æ–µ–∫—Ç\data\extracted\1.7.md"

if __name__ == "__main__":
    input_dir_arg = None
    output_dir_arg = None
    try:
        if len(sys.argv) == 2 and sys.argv[1].strip():
            input_dir_arg = sys.argv[1]
        elif len(sys.argv) == 3 and sys.argv[1].strip() and sys.argv[2].strip():
            input_dir_arg = sys.argv[1]
            output_dir_arg = sys.argv[2]
        else:
            input_dir_arg = DEFAULT_INPUT_FILE
            output_dir_arg = DEFAULT_OUTPUT_DIR

        md_path = Path(input_dir_arg)
        if not md_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_dir_arg}")

        if output_dir_arg:
            output_dir = Path(output_dir_arg)
            if not output_dir.exists():
                raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {output_dir_arg}")
            if not output_dir.is_dir():
                raise NotADirectoryError(f"–£–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {output_dir_arg}")
        else:
            output_dir = md_path.parent

        chunked_content = generate_chunked_file(input_dir_arg, output_dir)
    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python md_to_chunked.py <—Ñ–∞–π–ª.md> [output_dir]")
        sys.exit(1)
    except NotADirectoryError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python md_to_chunked.py <—Ñ–∞–π–ª.md> [output_dir]")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python md_to_chunked.py <—Ñ–∞–π–ª.md> [output_dir]")
        sys.exit(1)