=============================================================== 28.01.2026 23:36
Тема итогового проекта
"Разработка интеллектуального Telegram-бота на основе языковой модели для консультирования по нормативной документации в области электроэнергетики (ПУЭ, ПТЭЭП, ГОСТ)"
1. Предпосылки (почему выбрали именно эту тему?)
  Работая в энергетической отрасли, я ежедневно сталкиваюсь с ситуацией, когда инженерам, электромонтажникам и другим специалистам требуется оперативно найти ответ в нормативных документах — ПУЭ, ПТЭЭП и прочей нормативной документации по электроэнергетике
2. Описание задачи.
  Разработать интеллектуального Telegram-бота, способного:
  - Принимать вопросы пользователя на естественном русском языке по вопросам проектирования, монтажа и эксплуатации электроустановок;
  - Осуществлять семантический поиск пунктов нормативных документов (ПУЭ, ПТЭЭП, прочая нормативная документация по электроэнергетике);
  - Формировать структурированные ответы с точными ссылками на пункты, таблицы и рисунки документов;
3. Как видите ее решение
  База знаний — структурированные тексты ПУЭ, ПТЭЭП и ГОСТ с метаданными (раздел, пункт, статус требования: «обязательно» / «рекомендуется»).
  Векторное хранилище — локальная база для хранения эмбеддингов фрагментов документов.
  Языковая модель — для генерации ответов основной вариант: GigaChat, может быть развёрнута локальную бесплатную альтернативу модель Llama 3.1 8B через Ollama.
  Бот-платформа — асинхронный фреймворк Telegram Bot API.
  Хранение диалога — локальная СУБД SQLite для сохранения истории сообщений (возможна замена на Redis при необходимости повышения производительности).
4. Какую базу планируете использовать
   Предварительно - это Нормативная база электроэнергетики:
   - Правила устройства электроустановок 7-го издания (ПУЭ)
   - Правила технической эксплуатации электроустановок потребителей электрической энергии (ПТЭЭП)
   - прочая нормативная документация по электроэнергетике
=============================================================== 29.01.2026 16:30
=================== Ответ Куратора ============================
Куратор Анастасия Вишногорская (DS, GPT)
29 January 2026 (Thursday), 15:30
Добрый день, Александр! Тема утверждается при условии, что вы учтёте риски и сузите фокус на первом этапе.

Ключевые риски и моменты, требующие уточнения:

1. Объём данных и их подготовка: «Предварительно — это Нормативная база...» — это потенциально огромный объём неструктурированного текста (сотни страниц PDF). Самый трудоёмкий этап здесь — не написание бота, а предобработка документов: извлечение текста из PDF, разбиение на смысловые фрагменты (глава/пункт/подпункт), очистка, создание структуры с метаданными. На это может уйти 60-70% времени. Рекомендация: Начните с одного документа (например, ПУЭ, Раздел 1). Это позволит быстро отладить весь пайплайн.
2. Выбор языковой модели:
  - GigaChat/YandexGPT: Удобный API, но создаёт зависимость от внешнего сервиса, требует API-ключ и может нести затраты. Также есть вопрос о приватности запросов.
  - Локальная Llama 3.1 8B через Ollama: Полная независимость и приватность, но требует хорошего CPU/GPU (минимум 16 ГБ ОЗУ, лучше — GPU с 8+ ГБ памяти). Проверьте на своём железе, потянет ли она инференс с приемлемой скоростью. Для поиска и ответа по документам можно рассмотреть более лёгкие модели (например, Phi-3 mini, Mistral 7B).
3. Архитектура «сэндвича» (RAG — Retrieval-Augmented Generation): Вы её правильно описали: векторный поиск → LLM для генерации ответа. Это современный и адекватный подход. Нужно будет настроить чункер (разбиение текста) и метрику похожести для поиска.
Итог и рекомендации перед стартом:

 

Конкретные рекомендации:

1. Сузьте MVP: Чётко определить, что входит в первую версию. Например: *«Telegram-бот, работающий с Разделом 1 и Разделом 6 ПУЭ, на основе локально развёрнутой модели Llama 3.1 8B (или Phi-3)».*
2. Детализируйте план предобработки данных: Описать, как именно будут извлекаться и структурироваться данные из PDF (библиотеки: pymupdf, pdfplumber), как будут создаваться эмбеддинги (модель: sentence-transformers/all-MiniLM-L6-v2).
3. Протестируйте инференс модели: Убедиться, что выбранная LLM (особенно локальная) может стабильно генерировать связные ответы на тестовых примерах с предоставленным контекстом.

Резюме: Тема отличная, так как решает реальную проблему, имеет чёткие границы и позволяет продемонстрировать полный цикл работы с современным ML-стеком (векторные БД, RAG, LLM, боты). Главное — не утонуть в данных на старте и выбрать работоспособную модель.
==============================================================================
Учебник по Markdown
https://www.markdownlang.com/ru/advanced/math.html
https://markdown.com.cn/
https://marketplace.visualstudio.com/items?itemName=goessner.mdmath

Markdown+Math

https://code.visualstudio.com/docs/languages/python
==============================================================================
Архитектура системы:
```
┌─────────────────────────────────────────────────────────────────────┐
│                      ПАЙПЛАЙН ОБРАБОТКИ ДОКУМЕНТОВ                   │
└─────────────────────────────────────────────────────────────────────┘

┌──────────────┐
│  Исходники   │  ←  ./raw/
│ (PDF/DOCX)   │      • ПУЭ_7е_издание.pdf
└──────┬───────┘      • ПТЭЭП_2023.docx
       │
       ▼  [pdfplumber, python-docx, pandoc]
       │     └─► извлечение текста + форматирование в Markdown
       │
┌──────────────┐
│  extracted/  │  ←  ./extracted/
│   (*.md)     │      • pue_section_1.md
└──────┬───────┘      • pue_section_6.md
       │              • pteep_general.md
       ▼  [сегментация с метаданными]
       │     └─► разбивка по §/п. + извлечение:
       │          • номер раздела/главы/пункта
       │          • статус (обязательно/рекомендуется)
       │          • заголовок пункта
       │
┌──────────────┐
│  chunked/    │  ←  ./chunked/
│  (JSON/CSV)  │      [
└──────┬───────┘        {
       │                  "id": "pue_1.1.1",
       │                  "text": "Электроустановки...",
       │                  "section": "1.1",
       │                  "clause": "1.1.1",
       │                  "status": "mandatory",
       │                  "source_file": "pue_section_1.md"
       │                },
       │                ...
       │              ]
       ▼  [sentence-transformers/all-MiniLM-L6-v2]
       │
┌──────────────┐
│ embeddings/  │  ←  ./embeddings/
│ (Chroma DB)  │      • chroma.sqlite3, Milvus, Qdrant
└──────┬───────┘      • index/
       │
       ▼  [RAG-запрос]
┌──────────────┐
│ Telegram-бот │  ←  Поиск → Релевантные чанки → LLM (Llama 3.1 8B)
│  (Ollama)    │      → Структурированный ответ с ссылками на ПУЭ/ПТЭЭП
└──────────────┘
```

структура для итогового проекта

```
energy_norms_bot/
├── infra/
│   ├── docker/
│   │   ├── docker-compose.yml          # Основной compose для всех сервисов
│   │   ├── Dockerfile.bot              # Dockerfile для Telegram-бота
│   │   ├── Dockerfile.preprocessing    # Dockerfile для скриптов обработки
│   │   └── .env.example                # Пример переменных окружения
│   ├── milvus/
│   │   ├── docker-compose.milvus.yml   # Отдельный compose для Milvus
│   │   └── milvus.yaml                 # Конфигурация Milvus
│   └── ollama/
│       └── docker-compose.ollama.yml   # Compose для Ollama
├── src/
│   ├── bot/
│   ├── preprocessing/
│   │   ├── __init__.py
│   │   ├── create_md/
│   │   │   ├── __init__.py
│   │   │   ├── docx_to_md_images_1.py  # Конвертация DOCX → Markdown с изображениями
│   │   │   └── generator.py            # Массовая обработка документов
│   │   ├── create_chunked/
│   │   │   ├── __init__.py
│   │   │   ├── md_to_chunked_2.py      # Сегментация Markdown → JSON chunks
│   │   │   └── generator.py            # Массовая обработка чанков
│   │   └── create_embeddings/
│   │       ├── __init__.py
│   │       └── generator.py            # Генерация векторных представлений
│   └── rag/
├── data/
│   ├── raw/                            # Исходные документы (PDF/DOCX)
│   ├── extracted/                      # Извлеченный текст в Markdown
│   ├── chunked/                        # Сегментированные данные с метаданными
│   └── embeddings/                     # Векторная база данных (?????)
├── config/
│   ├── bot_config.yaml                 # Конфигурация бота
│   └── rag_config.yaml                 # Конфигурация RAG
├── requirements.txt
├── .gitignore
└── README.md



```